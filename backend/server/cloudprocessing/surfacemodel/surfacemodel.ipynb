{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import server.cloudprocessing.dataprocessing as dp\n",
    "import server.cloudprocessing.rnn as rnn\n",
    "import server.cloudprocessing.util as util\n",
    "import config as config\n",
    "import surfacemodel as sf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:15:23.821667Z",
     "start_time": "2023-11-17T07:15:23.816235Z"
    }
   },
   "id": "2e7c4dbf55512178"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data preparation\n",
    "extract current data from the database and prepare for processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3acda61db2d57078"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianrapp/PycharmProjects/nextgenbike/backend/server/cloudprocessing/dataprocessing.py:21: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  return pd.read_json(raw_data)\n"
     ]
    }
   ],
   "source": [
    "df = dp.get_dataframe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:15:30.680929Z",
     "start_time": "2023-11-17T07:15:25.006402Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asphalt Data points:  10089\n",
      "Pavement Data points:  3485\n",
      "Gravel Data points:  0\n",
      "Grass Data points:  20511\n",
      "Crash Data points:  6381\n",
      "                     time  trip_id  vibration  latitude  longitude  \\\n",
      "0 2023-11-16 17:20:55.454        1          1       0.0        0.0   \n",
      "1 2023-11-16 17:21:00.607        1          1       0.0        0.0   \n",
      "2 2023-11-16 17:21:00.659        1          1       0.0        0.0   \n",
      "3 2023-11-16 17:21:00.711        1          1       0.0        0.0   \n",
      "4 2023-11-16 17:21:00.763        1          1       0.0        0.0   \n",
      "\n",
      "   acceleration_x  acceleration_y  acceleration_z  gyroscope_x  gyroscope_y  \\\n",
      "0             261              -5              -5          -15           63   \n",
      "1             259               0              -8          -16           66   \n",
      "2             259               0              -9          -15           66   \n",
      "3             258               0              -8          -16           67   \n",
      "4             259               0              -9          -16           65   \n",
      "\n",
      "   gyroscope_z  crash  terrain  \n",
      "0          -48    0.0      NaN  \n",
      "1          -10    0.0      NaN  \n",
      "2           -6    0.0      NaN  \n",
      "3           -5    0.0      NaN  \n",
      "4          -15    0.0      NaN  \n"
     ]
    }
   ],
   "source": [
    "df = dp.pre_processing(df)\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:15:36.040875Z",
     "start_time": "2023-11-17T07:15:32.733932Z"
    }
   },
   "id": "7302fcc9477fce"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "descriptor 'timestamp' for 'pandas._libs.tslibs.timestamps._Timestamp' objects doesn't apply to a 'float' object",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X, Y \u001B[38;5;241m=\u001B[39m \u001B[43msf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_preparation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/nextgenbike/backend/server/cloudprocessing/surfacemodel/surfacemodel.py:21\u001B[0m, in \u001B[0;36mdata_preparation\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m     18\u001B[0m df\u001B[38;5;241m.\u001B[39mdropna(subset\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mterrain\u001B[39m\u001B[38;5;124m'\u001B[39m], inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     20\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime_second\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: pd\u001B[38;5;241m.\u001B[39mTimestamp(x)\u001B[38;5;241m.\u001B[39mfloor(freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m---> 21\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtime\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTimestamp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimestamp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m grouped \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mgroupby([df\u001B[38;5;241m.\u001B[39mtrip_id, df\u001B[38;5;241m.\u001B[39mtime_second])  \u001B[38;5;66;03m# grouped.get_group(1)\u001B[39;00m\n\u001B[1;32m     24\u001B[0m x, y \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/nextgenbike/backend/server/venv/lib/python3.9/site-packages/pandas/core/series.py:4540\u001B[0m, in \u001B[0;36mSeries.map\u001B[0;34m(self, arg, na_action)\u001B[0m\n\u001B[1;32m   4460\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\n\u001B[1;32m   4461\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4462\u001B[0m     arg: Callable \u001B[38;5;241m|\u001B[39m Mapping \u001B[38;5;241m|\u001B[39m Series,\n\u001B[1;32m   4463\u001B[0m     na_action: Literal[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   4464\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series:\n\u001B[1;32m   4465\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4466\u001B[0m \u001B[38;5;124;03m    Map values of Series according to an input mapping or function.\u001B[39;00m\n\u001B[1;32m   4467\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4538\u001B[0m \u001B[38;5;124;03m    dtype: object\u001B[39;00m\n\u001B[1;32m   4539\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4540\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_values, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;241m.\u001B[39m__finalize__(\n\u001B[1;32m   4542\u001B[0m         \u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmap\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4543\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/nextgenbike/backend/server/venv/lib/python3.9/site-packages/pandas/core/base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[0;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[1;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[0;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/nextgenbike/backend/server/venv/lib/python3.9/site-packages/pandas/core/algorithms.py:1814\u001B[0m, in \u001B[0;36mmap_array\u001B[0;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m   1812\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   1813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1814\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1815\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1816\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[1;32m   1817\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[1;32m   1818\u001B[0m     )\n",
      "File \u001B[0;32mlib.pyx:2920\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: descriptor 'timestamp' for 'pandas._libs.tslibs.timestamps._Timestamp' objects doesn't apply to a 'float' object"
     ]
    }
   ],
   "source": [
    "X, Y = sf.data_preparation(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:15:17.080951Z",
     "start_time": "2023-11-17T07:15:16.086380Z"
    }
   },
   "id": "a0400ab1a9478850"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb319204e1a5117d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def gen_dataloader(x, y, test_size=0.2, random_state=0):\n",
    "    # scaler = MinMaxScaler()  # TODO: choose scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x)\n",
    "    x = scaler.transform(x)\n",
    "\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    train_x = torch.Tensor(train_x)\n",
    "    train_y = F.one_hot(train_y.long(), len(config.classes)).to(torch.float32)\n",
    "\n",
    "    test_x = torch.Tensor(test_x)\n",
    "    test_y = F.one_hot(test_y.long(), len(config.classes)).to(torch.float32)\n",
    "\n",
    "    train_dataset = TensorDataset(train_x, train_y)\n",
    "    test_dataset = TensorDataset(test_x, test_y)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset)\n",
    "    test_loader = DataLoader(test_dataset)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "train_loader, test_loader = gen_dataloader(X, Y)  # with default values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:14:59.663834Z",
     "start_time": "2023-11-17T07:14:59.657949Z"
    }
   },
   "id": "28a848b118514c84"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training STARTED\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 46\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model, criterion\n\u001B[1;32m     45\u001B[0m model \u001B[38;5;241m=\u001B[39m rnn\u001B[38;5;241m.\u001B[39mRNN(config\u001B[38;5;241m.\u001B[39mn_training_cols, config\u001B[38;5;241m.\u001B[39mn_hidden_layers, \u001B[38;5;28mlen\u001B[39m(config\u001B[38;5;241m.\u001B[39mclasses))\n\u001B[0;32m---> 46\u001B[0m model, criterion \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[6], line 29\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, train_loader, num_epochs, lr, momentum)\u001B[0m\n\u001B[1;32m     26\u001B[0m         model_input \u001B[38;5;241m=\u001B[39m data_row[\u001B[38;5;28;01mNone\u001B[39;00m, i:i \u001B[38;5;241m+\u001B[39m config\u001B[38;5;241m.\u001B[39mn_training_cols]\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m     27\u001B[0m         output, hidden \u001B[38;5;241m=\u001B[39m model(model_input, hidden)\n\u001B[0;32m---> 29\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, target)\n\u001B[1;32m     31\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/PycharmProjects/nextgenbike/backend/server/venv/lib/python3.9/site-packages/torch/_compile.py:24\u001B[0m, in \u001B[0;36m_disable_dynamo.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(fn)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_dynamo\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dynamo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecursive\u001B[49m\u001B[43m)\u001B[49m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/PycharmProjects/nextgenbike/backend/server/venv/lib/python3.9/site-packages/torch/_dynamo/decorators.py:47\u001B[0m, in \u001B[0;36mdisable\u001B[0;34m(fn, recursive)\u001B[0m\n\u001B[1;32m     45\u001B[0m         fn \u001B[38;5;241m=\u001B[39m innermost_fn(fn)\n\u001B[1;32m     46\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(fn)\n\u001B[0;32m---> 47\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDisableContext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DisableContext()\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/nextgenbike/backend/server/venv/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:308\u001B[0m, in \u001B[0;36m_TorchDynamoContext.__call__\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    304\u001B[0m on_enter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_enter\n\u001B[1;32m    305\u001B[0m backend_ctx_ctor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mextra_ctx_ctor\n\u001B[1;32m    307\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;129;43m@functools\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwraps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m--> 308\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mdef\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;21;43m_fn\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDisableContext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_symbolic_trace\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_fx_tracing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_on_nested_fx_trace\u001B[49m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/functools.py:50\u001B[0m, in \u001B[0;36mupdate_wrapper\u001B[0;34m(wrapper, wrapped, assigned, updated)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_wrapper\u001B[39m(wrapper,\n\u001B[1;32m     36\u001B[0m                    wrapped,\n\u001B[1;32m     37\u001B[0m                    assigned \u001B[38;5;241m=\u001B[39m WRAPPER_ASSIGNMENTS,\n\u001B[1;32m     38\u001B[0m                    updated \u001B[38;5;241m=\u001B[39m WRAPPER_UPDATES):\n\u001B[1;32m     39\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Update a wrapper function to look like the wrapped function\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03m       wrapper is the function to be updated\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;124;03m       function (defaults to functools.WRAPPER_UPDATES)\u001B[39;00m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m assigned:\n\u001B[1;32m     51\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m             value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(wrapped, attr)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, num_epochs=config.num_training_epochs, lr=config.learning_rate,\n",
    "                momentum=config.momentum):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = nn.MSELoss()\n",
    "    # criterion = nn.NLLLoss()\n",
    "\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    print(\"Training STARTED\")\n",
    "\n",
    "    for e in range(0, num_epochs):\n",
    "        model.train()  # set the model in training mode\n",
    "        total_train_loss = 0  # initialize the total training and validation loss\n",
    "\n",
    "        for i, (training_input, target) in enumerate(train_loader):  # loop over the training set\n",
    "            hidden = model.initHidden()\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = [.0, .0, .0, .0]\n",
    "            for data_row in training_input:\n",
    "                for i in range(0, len(data_row), config.n_training_cols):\n",
    "                    model_input = data_row[None, i:i + config.n_training_cols].float()\n",
    "                    output, hidden = model(model_input, hidden)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # add the loss to the total training loss so far and calculate the number of correct predictions\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        if (e + 1) % 10 == 0:\n",
    "            print(\"Epoch\", e + 1, \"Training Loss:\", total_train_loss)\n",
    "\n",
    "    print(\"Training FINISHED\")\n",
    "\n",
    "    return model, criterion\n",
    "\n",
    "\n",
    "model = rnn.RNN(config.n_training_cols, config.n_hidden_layers, len(config.classes))\n",
    "model, criterion = train_model(model=model, train_loader=train_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T07:15:15.353632Z",
     "start_time": "2023-11-17T07:14:59.666661Z"
    }
   },
   "id": "e7b124385ff76145"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "530667021e47b60d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_training_accuracy(model, train_loader, criterion, classes):\n",
    "    training_loss, class_correct, class_total = util.compute_accuracy_rnn(model=model, loader=train_loader,\n",
    "                                                                      criterion=criterion)\n",
    "\n",
    "    # average training loss\n",
    "    training_loss = training_loss / len(train_loader.dataset)\n",
    "    print('Training Loss: {:.6f}\\n'.format(training_loss))\n",
    "    for i in range(len(classes)):\n",
    "        if class_total[i] > 0:\n",
    "            print('Training Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "                classes[i], 100.0 * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        else:\n",
    "            print('Training Accuracy of %5s: N/A ' % (classes[i]))\n",
    "\n",
    "    print('Training Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))\n",
    "\n",
    "\n",
    "print_training_accuracy(model=model, train_loader=train_loader, criterion=criterion, classes=config.classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T07:15:15.353209Z"
    }
   },
   "id": "62ce83cb80d2b080"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_testing_accuracy(model, test_loader, classes, criterion):\n",
    "    test_loss, class_correct, class_total = util.compute_accuracy_rnn(model=model, loader=test_loader, criterion=criterion)\n",
    "\n",
    "    # average test loss\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "                classes[i], 100.0 * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no testing examples)' % (classes[i]))\n",
    "\n",
    "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))\n",
    "\n",
    "\n",
    "print_testing_accuracy(model=model, test_loader=test_loader, criterion=criterion, classes=config.classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T07:15:15.354762Z"
    }
   },
   "id": "d71d827209b64b7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
