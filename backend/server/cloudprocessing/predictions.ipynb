{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianrapp/PycharmProjects/nextgenbike/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from requests.exceptions import ChunkedEncodingError\n",
    "\n",
    "import backend.config as config\n",
    "import dataprocessing as dp\n",
    "import rnn\n",
    "import util"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T06:34:15.192502Z",
     "start_time": "2023-11-16T06:34:14.135147Z"
    }
   },
   "id": "9f2335e918a19f11"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n",
      "                         time  trip_id  vibration  latitude  longitude  \\\n",
      "0  2023-11-05 17:35:18.484000        0          0       0.0        0.0   \n",
      "1  2023-11-05 17:35:18.537000        0          0       0.0        0.0   \n",
      "2  2023-11-05 17:35:18.589000        0          0       0.0        0.0   \n",
      "3  2023-11-05 17:35:18.641000        0          0       0.0        0.0   \n",
      "4  2023-11-05 17:35:24.245000        0          0       0.0        0.0   \n",
      "\n",
      "   acceleration_x  acceleration_y  acceleration_z  gyroscope_x  gyroscope_y  \\\n",
      "0             260              15             -53           51           54   \n",
      "1             259              13             -56           16           22   \n",
      "2             262               6             -57          -20           78   \n",
      "3             255               8             -54            1          -11   \n",
      "4             258               9             -58          -10           64   \n",
      "\n",
      "   gyroscope_z  crash  terrain  \n",
      "0           21    NaN      NaN  \n",
      "1          208    NaN      NaN  \n",
      "2          -76    NaN      NaN  \n",
      "3            4    NaN      NaN  \n",
      "4           -4    NaN      NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q4/b_qkk2qx16zdglt42g7c0dlr0000gn/T/ipykernel_86754/4023679038.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframe = pd.read_json(raw_data)\n"
     ]
    }
   ],
   "source": [
    "raw_data = \"\"\n",
    "while raw_data == \"\":\n",
    "    try:\n",
    "        raw_data = dp.get_data_db()\n",
    "    except ChunkedEncodingError:\n",
    "        print(\"Couldn't get Data, retrying ...\")\n",
    "\n",
    "dataframe = pd.read_json(raw_data)\n",
    "print(dataframe.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T06:34:20.229139Z",
     "start_time": "2023-11-16T06:34:16.921856Z"
    }
   },
   "id": "ac39337a279846a2"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-16T06:53:19.461779Z",
     "start_time": "2023-11-16T06:53:19.324587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1970-01-01 00:00:00\n",
      "207\n",
      "1970-01-01 00:00:00\n",
      "208\n",
      "1970-01-01 00:00:00\n",
      "209\n",
      "1970-01-01 00:00:00\n",
      "210\n",
      "1970-01-01 00:00:00\n",
      "211\n",
      "1970-01-01 00:00:00\n",
      "212\n",
      "1970-01-01 00:00:00\n",
      "213\n",
      "1970-01-01 00:00:00\n",
      "214\n",
      "1970-01-01 00:00:00\n",
      "215\n",
      "1970-01-01 00:00:00\n",
      "216\n",
      "1970-01-01 00:00:00\n",
      "217\n",
      "1970-01-01 00:00:00\n",
      "218\n",
      "1970-01-01 00:00:00\n",
      "219\n",
      "1970-01-01 00:00:00\n",
      "220\n",
      "1970-01-01 00:00:00\n",
      "221\n",
      "1970-01-01 00:00:00\n",
      "222\n",
      "1970-01-01 00:00:00\n",
      "223\n",
      "1970-01-01 00:00:00\n",
      "224\n",
      "1970-01-01 00:00:00\n",
      "225\n",
      "1970-01-01 00:00:00\n",
      "226\n",
      "1970-01-01 00:00:00\n",
      "227\n",
      "1970-01-01 00:00:00\n",
      "228\n",
      "1970-01-01 00:00:00\n",
      "229\n",
      "1970-01-01 00:00:00\n",
      "230\n",
      "1970-01-01 00:00:00\n",
      "231\n",
      "1970-01-01 00:00:00\n",
      "232\n",
      "1970-01-01 00:00:00\n",
      "233\n",
      "1970-01-01 00:00:00\n",
      "234\n",
      "1970-01-01 00:00:00\n",
      "235\n",
      "1970-01-01 00:00:00\n",
      "245\n",
      "1970-01-01 00:00:00\n",
      "255\n",
      "1970-01-01 00:00:00\n",
      "265\n",
      "1970-01-01 00:00:00\n",
      "275\n",
      "1970-01-01 00:00:00\n",
      "285\n",
      "1970-01-01 00:00:00\n",
      "295\n",
      "1970-01-01 00:00:00\n",
      "305\n",
      "1970-01-01 00:00:00\n",
      "306\n",
      "1970-01-01 00:00:00\n",
      "307\n",
      "1970-01-01 00:00:00\n",
      "308\n",
      "1970-01-01 00:00:00\n",
      "309\n",
      "1970-01-01 00:00:00\n",
      "310\n",
      "1970-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "dataframe['time'] = pd.to_datetime(dataframe['time'], format='mixed')\n",
    "dataframe['time_second'] = dataframe.time.map(lambda x: pd.Timestamp(x).floor(freq='S'))\n",
    "dataframe['time'] = dataframe.time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "grouped = dataframe.groupby([dataframe.trip_id, dataframe.time_second])  # grouped.get_group(1)\n",
    "x = []\n",
    "id_list, time_list, lat_list, lon_list = [], [], [], []\n",
    "\n",
    "for i, (trip_seconds, table) in enumerate(grouped):\n",
    "    time_list.append(trip_seconds[0])\n",
    "    id_list.append(trip_seconds[1])\n",
    "    lat_list.append(table['latitude'].mean())\n",
    "    lon_list.append(table['longitude'].mean())\n",
    "\n",
    "    train_input = table.drop(columns=['terrain', 'trip_id', 'crash', 'time_second', 'latitude', 'longitude'])\n",
    "    if len(train_input.columns) != config.n_training_cols:\n",
    "        raise Exception(\"Wrong number of input columns (should be)\", config.n_training_cols,\n",
    "                        \", please check data.\\n\"\n",
    "                        \"But input was: \", train_input)\n",
    "\n",
    "    train_input = train_input.to_numpy()\n",
    "\n",
    "    input_length = len(train_input)\n",
    "    if input_length > config.batch_size:\n",
    "        train_input = train_input[:config.batch_size]\n",
    "    else:\n",
    "        n_missing_rows = config.batch_size - len(train_input)\n",
    "        for _ in range(n_missing_rows):\n",
    "            fake_array = [1] * config.n_training_cols\n",
    "            train_input = np.append(train_input, fake_array)\n",
    "\n",
    "    x.append(train_input)\n",
    "\n",
    "\n",
    "\n",
    "y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7541f64e31af89a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
