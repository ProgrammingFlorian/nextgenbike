{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianrapp/PycharmProjects/nextgenbike/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from requests.exceptions import ChunkedEncodingError\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import dataprocessing as dp\n",
    "import backend.config as config\n",
    "import rnn\n",
    "import util"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T06:04:15.999205Z",
     "start_time": "2023-11-16T06:04:14.539778Z"
    }
   },
   "id": "9f2335e918a19f11"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n",
      "Couldn't get Data, retrying ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q4/b_qkk2qx16zdglt42g7c0dlr0000gn/T/ipykernel_86441/2652575126.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframe = pd.read_json(raw_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asphalt Data points:  1257\n",
      "Pavement Data points:  752\n",
      "Gravel Data points:  0\n",
      "Grass Data points:  886\n",
      "\n",
      "Crash Data points:  0\n",
      "                     time  trip_id  vibration  latitude  longitude  \\\n",
      "0 2023-11-05 17:35:18.484        0          0       0.0        0.0   \n",
      "1 2023-11-05 17:35:18.537        0          0       0.0        0.0   \n",
      "2 2023-11-05 17:35:18.589        0          0       0.0        0.0   \n",
      "3 2023-11-05 17:35:18.641        0          0       0.0        0.0   \n",
      "4 2023-11-05 17:35:24.245        0          0       0.0        0.0   \n",
      "\n",
      "   acceleration_x  acceleration_y  acceleration_z  gyroscope_x  gyroscope_y  \\\n",
      "0             260              15             -53           51           54   \n",
      "1             259              13             -56           16           22   \n",
      "2             262               6             -57          -20           78   \n",
      "3             255               8             -54            1          -11   \n",
      "4             258               9             -58          -10           64   \n",
      "\n",
      "   gyroscope_z  crash  terrain  \n",
      "0           21    0.0      NaN  \n",
      "1          208    0.0      NaN  \n",
      "2          -76    0.0      NaN  \n",
      "3            4    0.0      NaN  \n",
      "4           -4    0.0      NaN  \n"
     ]
    }
   ],
   "source": [
    "raw_data = \"\"\n",
    "while raw_data == \"\":\n",
    "    try:\n",
    "        raw_data = dp.get_data_db()\n",
    "    except ChunkedEncodingError:\n",
    "        print(\"Couldn't get Data, retrying ...\")\n",
    "\n",
    "dataframe = pd.read_json(raw_data)\n",
    "print(dataframe.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T06:18:31.644005Z",
     "start_time": "2023-11-16T06:18:23.759149Z"
    }
   },
   "id": "ac39337a279846a2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-16T06:06:07.112895Z",
     "start_time": "2023-11-16T06:06:07.080607Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'time_second'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/q4/b_qkk2qx16zdglt42g7c0dlr0000gn/T/ipykernel_86441/2877296610.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mgrouped\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdataframe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroupby\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdataframe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrip_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataframe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime_second\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# grouped.get_group(1)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtrip_seconds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtable\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrouped\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/nextgenbike/venv/lib/python3.9/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   6200\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6201\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6202\u001B[0m         ):\n\u001B[1;32m   6203\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6204\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'time_second'"
     ]
    }
   ],
   "source": [
    "df['time_second'] = df.time.map(lambda x: pd.Timestamp(x).floor(freq='S'))\n",
    "df['time'] = df.time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "grouped = dataframe.groupby([dataframe.trip_id, dataframe.time_second])  # grouped.get_group(1)\n",
    "x = []\n",
    "\n",
    "for i, (trip_seconds, table) in enumerate(grouped):\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(\"# trip seconds: \" + str(i + 1))\n",
    "\n",
    "    train_input = table.drop(columns=['terrain', 'trip_id', 'crash', 'time_second', 'latitude', 'longitude'])\n",
    "    if len(train_input.columns) != config.n_training_cols:\n",
    "        raise Exception(\"Wrong number of input columns (should be)\", config.n_training_cols,\n",
    "                        \", please check data.\\n\"\n",
    "                        \"But input was: \", train_input)\n",
    "\n",
    "    train_input = train_input.to_numpy()\n",
    "\n",
    "    input_length = len(train_input)\n",
    "    if input_length > config.batch_size:\n",
    "        train_input = train_input[:config.batch_size]\n",
    "    else:\n",
    "        n_missing_rows = config.batch_size - len(train_input)\n",
    "        for _ in range(n_missing_rows):\n",
    "            fake_array = [1] * config.n_training_cols\n",
    "            train_input = np.append(train_input, fake_array)\n",
    "\n",
    "    x.append(train_input)\n",
    "\n",
    "lat_list = grouped.latitude.mean()\n",
    "print(lat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7541f64e31af89a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
